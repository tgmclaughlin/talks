





# it's the end of the (hello) world as we know it. (and I feel fine)







## whoami
- tom mclaughlin
- applied ai solutions architect
- tomoro.ai










---







## tomoro ai


### what
- applied AI consultancy
- build cutting-edge generative AI solutions for enterprise clients [insert rolodex of household names]
- scale to [insert impressive metric here]


### how
- working as lean engineering teams (2/3 people)
- deeply embedded into our client problems and processes 
- build MVP to prod in < 12 weeks
- verify 
- scale 







---

## how did we get here
idea behind this section is speed of adaptation. line of thought follows:
- exams: failure -> fit
- uni: failure -> fit
- jp: failure -> fit
- start ups: failure -> fit

ml analogy throughout: you want to fit - generalise, but not overfit










### school
- lazy kid
- loved games
- bombed exams
- realised there was a system to exams after that: get good at past papers
- ended up loving maths, physics, cs
- converted to 6 decent A grades following year (from BCC)












### uni
- cs @ strath 
- riding off success of 6th year
- too easy
- until 2nd year exams
- bombed again
- reached out to lecturers 
- low and behold: past papers again
- tooooo easy











### getting a 'real job'
- jp morgan swe
- 4 years 
- riding off my degree world tour celebration
- goal post change
  - uni java =/= corporate java
  - promotion??
  - politics??

- **play the game.**
- or not?










### crypto billions or bust / nft / sbf / lambos all round
- obsessed by the domain 
- technically decent 
- but priority is to build fast **(now or sooner)**
- u-turn on the corporate way of building 
  - (lets have a planning session in two weeks)

- pivot after 7 months
  - wasn't passionate about the domain
  - this is key 
  - fast verify (sort of: 4 years -> 7 months)








  


### to protect and serve / playing 007 / turns out you can check into hotels with just 'm'
- boutique defence consultancy 
- gov sector
- extremely high quality of engineering
  - learned from some great engineers here
- low/no risk profile

- loved it here - cool mission, good culture

- got acquired by large american consultancy











---


### interlude - what's this chatgpt thing all about
- who remembers their first time?
- what about first time getting code from it?
  - what an adventure that was

- have used chatgpt or equivalent every day since nov 2022 (check this)

- "if this gets better it's going to change things in a big way"

- used it for docs 
- used it for writing code
- used it for reviewing code
- used it for architecting
- used it for learning 
- used it to make calls
- used it to automatically generate CVs specific to job descriptions
- even used it to check this presentation

- "but we shouldn't use it to generate documentation"
  - what???

- **story time**


- time to find a new dataset to fit to...




---







### contract consulting
- what needs built
- how long will it take
- how many people
- what will it cost
- what is the roi on that
- how do you sell that business case

- big fit to business


- but...
- surely businesses don't actually work like this
- they do.











### mate what are you on about? who cares?

- golden thread (using ml analogy)

- how do machines learn?
  
  - each of these experience is a training set:
  
  - in some cases we underfit to that set
    - typically before failing exams
    
  - in others we see overfit
    - usually after passing exams
    
  - sometimes we even see a **good** fit
    - like realising gen ai was going to be mega high leverage







---





### this was meant to be a talk about what skills matter now, was it not?
- yes, so here it is:





** adaptability ** aka rate of learning













---








## thanks for coming to my talk!
- any questions?
- find me on linkedin:
  - /in/aibuilder










---








### insert picture slide of charles darwin before asking the audience if anyone can tell me who this is

- quote the bit about 

  - "it isn't the fittest/strongest/smartest that survive, it is those who adapt fastest"
  
- proceed to lead audience down the rabbit hole 

- make wild claim that my theory is essentially the theory of evolution 


off record: adapt to what?? environment








---









### if adaptation is key, how can we optimise for it?


- my thesis is that we learn in a not dissimilar way to how machines learn

- so we could look there for advice













---









### so what works for machines?





- quality of evaluation metrics
  - what gets measured gets improved



- quality of data
  - garbage in garbage out



- once you have that, the training is the really easy part

  
  











---





### where do we get the evals?

- this is your concept of 'fitness'

- what makes someone good at [insert role here]
  
  - being a student?
    - exam scoring
    - dissertation writing

  - working as a software engineer?
    - writing good software
    - working with others
    - playing the politics a bit

  - working at a crypto start up?
    - speed of execution
    - domain obsession

  - working in defence consultancy?
    - solid engineering skills
    - ability to reduce risk 
    - 

  - working at tomoro?



  

---






### we have our evals, how do we improve the model?


- we need our dataset of examples
  - "what does good look like?"
  - "what does bad look like?"
  

- we want roughly the same amount of examples from each side
  - why?
  - adrian driving instructor analogy: you always go too slow 
    - i want you to go faster so i get to tell you to slow down
  - you need a boundary at each side (use hands to show that narrowing)











---







### sourcing your **high quality** dataset

- the whole point in this section will be around exposure:
  - bad examples are fairly trivial to come by
  - good examples are harder - you need to seek them out

- how do we seek? or where?
  - hackathons
  - conferences (like this one)
  - meet up groups
  - start ups
  - accelerators: ef/yc etc etc

  - really, it depends on your evals - but this is what has worked for me

- the more exposure you can get the more you can build out that dataset of what does good look like in your domain
  of fitness and start to train on it







---




### gen ai / chatgpt makes this way easier

- i use the full hour per day allowance of chatgpt adv voice mode
  - why wouldn't you?
    - it's essentially an hour with a private tutor on the subject of your choice every day


- certain models are great at gathering this dataset for specific domains
  - right now:
    - claude is excellent at writing code and doing architecture planning/reviews

    - gemini is leading the way in deep research (again - exposure)

    - openai for voice interactions is winning

    - elevenlabs likely in the same bucket








---


### next steps to accelerate learning rate?


- systemize your metrics:
  - for environment x, what does good look like?
    - technical skills
    - soft skills


- start the data collection process to build your training set:
  - good examples:

    - get involved in a hackathon
    - go to a meet up group
    - go to a conference
    - speak to people on linkedin etc etc who you think are working in that sector. pick their brain
    - go all out and apply for ef/yc etc
  
    - surround yourself with good data

  - bad examples:
    - don't worry about hunting for them, you'll know it when you see it


---













## thanks for coming to my talk! (for real this time)
- find me on linkedin:
  - /in/aibuilder


- any questions?










































